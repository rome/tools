# CLI benchmark, compares main and PR branch with Hyperfine.
# Comment with text containing `!bench_cli`, a new result will be commented at the bottom of this PR.

name: CLI Benchmark

on:
  issue_comment:
    types: [ created ]

env:
  RUST_LOG: info

jobs:
  bench:
    name: Bench
    if: github.event.issue.pull_request && contains(github.event.comment.body, '!bench_cli')
    runs-on: ubuntu-latest

    steps:
      - name: Get PR SHA
        id: sha
        uses: actions/github-script@v6
        with:
          result-encoding: string
          script: |
            const response = await github.request(context.payload.issue.pull_request.url);
            return response.data.head.sha;

      - name: Checkout PR Branch
        uses: actions/checkout@v3
        with:
          submodules: false
          ref: ${{ steps.sha.outputs.result }}

      - name: Install toolchain
        run: rustup show

      - name: Cache
        uses: Swatinem/rust-cache@v2

      - name: Install hyperfine
        run: cargo install hyperfine

      - name: Compile on PR Branch
        run: |
          cargo build --release --bin rome
          mkdir -p benchmark/target
          cp target/release/rome benchmark/target/rome_pr

      - name: Checkout Main Branch
        uses: actions/checkout@v3
        with:
          clean: false
          ref: main

      - name: Compile on Main Branch
        run: |
          cargo build --release --bin rome
          cp target/release/rome benchmark/target/rome_main

      - name: Checkout webpack
        uses: actions/checkout@v3
        with:
          repository: webpack/webpack
          path: benchmark/target/webpack
      - name: Checkout prettier
        uses: actions/checkout@v3
        with:
          repository: prettier/prettier
          path: benchmark/target/prettier
      - name: Checkout eslint
        uses: actions/checkout@v3
        with:
          repository: eslint/eslint
          path: benchmark/target/eslint

      - name: Run Benchmarks
        id: benchmarks
        working-directory: benchmark/target
        env:
          FORMAT_BENCH_COMMAND: "format webpack/lib webpack/examples webpack/declarations webpack/benchmark prettier/src prettier/scripts --write"
          CHECK_BENCH_COMMAND: "--max-diagnostics=0 eslint/lib eslint/messages eslint/tests/lib eslint/tests/performance eslint/tools webpack/lib"
        run: |
          hyperfine -w 2 --export-markdown benchmark_format.md \
            -n "rome format (main)" "./rome_main $FORMAT_BENCH_COMMAND" \
            -n "rome format (pr)" "./rome_pr $FORMAT_BENCH_COMMAND"
          hyperfine -w 2 --export-markdown benchmark_check.md \
            -n "rome check (main)" "./rome_main check $CHECK_BENCH_COMMAND" \
            -n "rome check (pr)" "./rome_pr check $CHECK_BENCH_COMMAND"
          cat benchmark_format.md >> benchmark.md
          echo $'\n' >> benchmark.md
          cat benchmark_check.md >> benchmark.md

      - name: Write a new comment
        uses: peter-evans/create-or-update-comment@v2
        continue-on-error: true
        with:
          issue-number: ${{ github.event.issue.number }}
          body-file: benchmark/target/benchmark.md
